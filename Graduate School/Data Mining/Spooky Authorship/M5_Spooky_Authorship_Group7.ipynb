{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vf3wUioLbgzc"
      },
      "source": [
        "- Type your name on a code block to indicate if you are still working on the codes.\n",
        "- Try running codes in a separate Colab file to test the results and then copy the codes in this main file.\n",
        "- I am using Kaggle API to download the data. Use your own API token from Kaggle to run the codes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YiYa44LXcWhw"
      },
      "source": [
        "Stage 0 - Import: Completed (Shaon)\n",
        "Stage 1- Data Prep: Shaon (will work from Friday night)/ Jacob\n",
        "Stage 2 - Feature Extraction (Jacob)\n",
        "Stage 3 - Machine Learning (Alex)\n",
        "Stage 4 - Evaluation (Nelson)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "4KdSiQzJR7g_",
        "outputId": "1e95f562-1e17-46ab-a53c-493e253c5f15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Upload your Kaggle API .JSON File\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f7604cfe-6be3-4edd-ab0a-4032113de0ec\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f7604cfe-6be3-4edd-ab0a-4032113de0ec\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle (1).json\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'kaggle (1).json': b'{\"username\":\"mshaon\",\"key\":\"0598fced3b3a9586d32b772969c5c789\"}'}"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Upload Kaggle API file\n",
        "from google.colab import files\n",
        "print (\"Upload your Kaggle API .JSON File\")\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sDfR4ugQTykm"
      },
      "outputs": [],
      "source": [
        "# Move API to appropriate folder\n",
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sm94zigdUNbl",
        "outputId": "8200f1c5-28a3-492c-9b60-33904202ed28"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "spooky-author-identification.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ],
      "source": [
        "# Download target data\n",
        "!kaggle competitions download -c spooky-author-identification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vM1kA1lgUvmj",
        "outputId": "4e7c7b94-66a2-431e-8403-c2a92c8e2ea3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "replace sample_submission.zip? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace test.zip? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace train.zip? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace train.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace test.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace sample_submission.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n"
          ]
        }
      ],
      "source": [
        "# Unzip the main competition archive (this might contain all the others)\n",
        "!unzip -q spooky-author-identification.zip\n",
        "\n",
        "# Unzip individual components (if they weren't in the main archive, or just to be sure)\n",
        "!unzip -q train.zip\n",
        "!unzip -q test.zip\n",
        "!unzip -q sample_submission.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QAsrjWFtUyud",
        "outputId": "84b0d976-f6d3-4b50-da67-921c809ce41d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'kaggle (1).json'\t sample_submission.zip\t\t    test.zip\n",
            " sample_data\t\t spooky-author-identification.zip   train.csv\n",
            " sample_submission.csv\t test.csv\t\t\t    train.zip\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-F_oRVRKRkr",
        "outputId": "b30f95ac-fd3d-48a1-f57e-9ac7d6e7210b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.1)\n",
            "Collecting findspark\n",
            "  Downloading findspark-2.0.1-py2.py3-none-any.whl.metadata (352 bytes)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n",
            "Downloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n",
            "Installing collected packages: findspark\n",
            "Successfully installed findspark-2.0.1\n"
          ]
        }
      ],
      "source": [
        "# Install PySpark and FindSpark\n",
        "!pip install pyspark findspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dYmMMFsbKY3J"
      },
      "outputs": [],
      "source": [
        "# Initialize FindSpark\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "# Import SparkSession\n",
        "from pyspark.sql import SparkSession"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ko0ymPKqKb7b"
      },
      "outputs": [],
      "source": [
        "# Create a SparkSession\n",
        "spark = SparkSession.builder.appName(\"SpookyAuthorship\").getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2M1lqH_IK9OS",
        "outputId": "f361cae7-99b7-4ba1-b4e5-258e94864e42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Data Schema:\n",
            "root\n",
            " |-- id: string (nullable = true)\n",
            " |-- text: string (nullable = true)\n",
            " |-- author: string (nullable = true)\n",
            "\n",
            "\n",
            "Train Data Sample:\n",
            "+-------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------+\n",
            "|id     |text                                                                                                                                                                                                                                   |author|\n",
            "+-------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------+\n",
            "|id26305|This process, however, afforded me no means of ascertaining the dimensions of my dungeon; as I might make its circuit, and return to the point whence I set out, without being aware of the fact; so perfectly uniform seemed the wall.|EAP   |\n",
            "|id17569|It never once occurred to me that the fumbling might be a mere mistake.                                                                                                                                                                |HPL   |\n",
            "|id11008|In his left hand was a gold snuff box, from which, as he capered down the hill, cutting all manner of fantastic steps, he took snuff incessantly with an air of the greatest possible self satisfaction.                               |EAP   |\n",
            "|id27763|How lovely is spring As we looked from Windsor Terrace on the sixteen fertile counties spread beneath, speckled by happy cottages and wealthier towns, all looked as in former years, heart cheering and fair.                         |MWS   |\n",
            "|id12958|Finding nothing else, not even gold, the Superintendent abandoned his attempts; but a perplexed look occasionally steals over his countenance as he sits thinking at his desk.                                                         |HPL   |\n",
            "+-------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------+\n",
            "only showing top 5 rows\n",
            "\n",
            "\n",
            "Test Data Schema:\n",
            "root\n",
            " |-- id: string (nullable = true)\n",
            " |-- text: string (nullable = true)\n",
            "\n",
            "\n",
            "Test Data Sample:\n",
            "+-------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|id     |text                                                                                                                                                                                                                                                                                                                                      |\n",
            "+-------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|id02310|Still, as I urged our leaving Ireland with such inquietude and impatience, my father thought it best to yield.                                                                                                                                                                                                                            |\n",
            "|id24541|If a fire wanted fanning, it could readily be fanned with a newspaper, and as the government grew weaker, I have no doubt that leather and iron acquired durability in proportion, for, in a very short time, there was not a pair of bellows in all Rotterdam that ever stood in need of a stitch or required the assistance of a hammer.|\n",
            "|id00134|And when they had broken down the frail door they found only this: two cleanly picked human skeletons on the earthen floor, and a number of singular beetles crawling in the shadowy corners.                                                                                                                                             |\n",
            "|id27757|While I was thinking how I should possibly manage without them, one actually tumbled out of my head, and, rolling down the steep side of the steeple, lodged in the rain gutter which ran along the eaves of the main building.                                                                                                           |\n",
            "|id04081|I am not sure to what limit his knowledge may extend.                                                                                                                                                                                                                                                                                     |\n",
            "+-------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "\n",
            "Train Data Size: 19579 rows\n",
            "Test Data Size: 8392 rows\n",
            "\n",
            "Author Distribution in Training Data:\n",
            "+--------------------+-----+\n",
            "|              author|count|\n",
            "+--------------------+-----+\n",
            "| I'm all soul and...|    1|\n",
            "| and the supposit...|    1|\n",
            "|\"\" who preached a...|    1|\n",
            "| at this period o...|    1|\n",
            "| \"\"It gave me the...|    1|\n",
            "| that these Blasp...|    1|\n",
            "|      Madame Lalande|    1|\n",
            "| and I cannot con...|    1|\n",
            "| one of the \"\"Eng...|    1|\n",
            "| you have straigh...|    1|\n",
            "| and we continued...|    1|\n",
            "| and in a few bri...|    1|\n",
            "|      and very happy|    1|\n",
            "| turning abruptly...|    1|\n",
            "| who art called o...|    1|\n",
            "| who gave me this...|    1|\n",
            "|       Mr. Wyatt.\"\"\"|    1|\n",
            "|           Woodville|    1|\n",
            "| and returned wit...|    1|\n",
            "|  thet Afriky book?\"|    1|\n",
            "+--------------------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Load the training data\n",
        "train_df = spark.read.csv(\"train.csv\", header=True, inferSchema=True)\n",
        "\n",
        "# Load the test data\n",
        "test_df = spark.read.csv(\"test.csv\", header=True, inferSchema=True)\n",
        "\n",
        "# Display schema and show a few rows of the training data\n",
        "print(\"Train Data Schema:\")\n",
        "train_df.printSchema()\n",
        "print(\"\\nTrain Data Sample:\")\n",
        "train_df.show(5, truncate=False)\n",
        "\n",
        "# Display schema and show a few rows of the test data\n",
        "print(\"\\nTest Data Schema:\")\n",
        "test_df.printSchema()\n",
        "print(\"\\nTest Data Sample:\")\n",
        "test_df.show(5, truncate=False)\n",
        "\n",
        "# Display the size of the dataframes\n",
        "print(f\"\\nTrain Data Size: {train_df.count()} rows\")\n",
        "print(f\"Test Data Size: {test_df.count()} rows\")\n",
        "\n",
        "# Check distribution of authors in training data\n",
        "print(\"\\nAuthor Distribution in Training Data:\")\n",
        "train_df.groupBy(\"author\").count().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6TV6uiOGLZzV",
        "outputId": "c69ce108-fd38-491b-a922-b6777113dcec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data after lowercasing and special character removal (Train):\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|text                                                                                                                                                                                                                                   |cleaned_text                                                                                                                                                                                                                    |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|This process, however, afforded me no means of ascertaining the dimensions of my dungeon; as I might make its circuit, and return to the point whence I set out, without being aware of the fact; so perfectly uniform seemed the wall.|this process however afforded me no means of ascertaining the dimensions of my dungeon as i might make its circuit and return to the point whence i set out without being aware of the fact so perfectly uniform seemed the wall|\n",
            "|It never once occurred to me that the fumbling might be a mere mistake.                                                                                                                                                                |it never once occurred to me that the fumbling might be a mere mistake                                                                                                                                                          |\n",
            "|In his left hand was a gold snuff box, from which, as he capered down the hill, cutting all manner of fantastic steps, he took snuff incessantly with an air of the greatest possible self satisfaction.                               |in his left hand was a gold snuff box from which as he capered down the hill cutting all manner of fantastic steps he took snuff incessantly with an air of the greatest possible self satisfaction                             |\n",
            "|How lovely is spring As we looked from Windsor Terrace on the sixteen fertile counties spread beneath, speckled by happy cottages and wealthier towns, all looked as in former years, heart cheering and fair.                         |how lovely is spring as we looked from windsor terrace on the sixteen fertile counties spread beneath speckled by happy cottages and wealthier towns all looked as in former years heart cheering and fair                      |\n",
            "|Finding nothing else, not even gold, the Superintendent abandoned his attempts; but a perplexed look occasionally steals over his countenance as he sits thinking at his desk.                                                         |finding nothing else not even gold the superintendent abandoned his attempts but a perplexed look occasionally steals over his countenance as he sits thinking at his desk                                                      |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "\n",
            "Data after lowercasing and special character removal (Test):\n",
            "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|text                                                                                                                                                                                                                                                                                                                                      |cleaned_text                                                                                                                                                                                                                                                                                                                       |\n",
            "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|Still, as I urged our leaving Ireland with such inquietude and impatience, my father thought it best to yield.                                                                                                                                                                                                                            |still as i urged our leaving ireland with such inquietude and impatience my father thought it best to yield                                                                                                                                                                                                                        |\n",
            "|If a fire wanted fanning, it could readily be fanned with a newspaper, and as the government grew weaker, I have no doubt that leather and iron acquired durability in proportion, for, in a very short time, there was not a pair of bellows in all Rotterdam that ever stood in need of a stitch or required the assistance of a hammer.|if a fire wanted fanning it could readily be fanned with a newspaper and as the government grew weaker i have no doubt that leather and iron acquired durability in proportion for in a very short time there was not a pair of bellows in all rotterdam that ever stood in need of a stitch or required the assistance of a hammer|\n",
            "|And when they had broken down the frail door they found only this: two cleanly picked human skeletons on the earthen floor, and a number of singular beetles crawling in the shadowy corners.                                                                                                                                             |and when they had broken down the frail door they found only this two cleanly picked human skeletons on the earthen floor and a number of singular beetles crawling in the shadowy corners                                                                                                                                         |\n",
            "|While I was thinking how I should possibly manage without them, one actually tumbled out of my head, and, rolling down the steep side of the steeple, lodged in the rain gutter which ran along the eaves of the main building.                                                                                                           |while i was thinking how i should possibly manage without them one actually tumbled out of my head and rolling down the steep side of the steeple lodged in the rain gutter which ran along the eaves of the main building                                                                                                         |\n",
            "|I am not sure to what limit his knowledge may extend.                                                                                                                                                                                                                                                                                     |i am not sure to what limit his knowledge may extend                                                                                                                                                                                                                                                                               |\n",
            "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Import necessary PySpark functions and libraries\n",
        "from pyspark.sql.functions import lower, regexp_replace, udf\n",
        "from pyspark.sql.types import ArrayType, StringType\n",
        "from pyspark.ml.feature import Tokenizer, StopWordsRemover\n",
        "import re\n",
        "\n",
        "# --- Data Preprocessing ---\n",
        "\n",
        "# 1. Convert text to lowercase and remove special characters\n",
        "# Define a UDF for cleaning text (removing special characters and extra spaces)\n",
        "def clean_text_udf(text):\n",
        "    if text is None:\n",
        "        return None\n",
        "    # Remove non-alphanumeric characters (keeping spaces)\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    # Replace multiple spaces with a single space\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "# Register the UDF\n",
        "clean_text = udf(clean_text_udf, StringType())\n",
        "\n",
        "# Apply lowercase and cleaning to the 'text' column for both train and test DataFrames\n",
        "# Ensure the 'text' column is converted to string type before applying lower()\n",
        "train_df = train_df.withColumn(\"cleaned_text\", clean_text(lower(train_df[\"text\"].cast(StringType()))))\n",
        "test_df = test_df.withColumn(\"cleaned_text\", clean_text(lower(test_df[\"text\"].cast(StringType()))))\n",
        "\n",
        "print(\"Data after lowercasing and special character removal (Train):\")\n",
        "train_df.select(\"text\", \"cleaned_text\").show(5, truncate=False)\n",
        "print(\"\\nData after lowercasing and special character removal (Test):\")\n",
        "test_df.select(\"text\", \"cleaned_text\").show(5, truncate=False)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lx6lnbvSLa5e",
        "outputId": "adc5c451-8046-49e7-d75f-f5f1498b2dab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Data after Tokenization (Train):\n",
            "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|cleaned_text                                                                                                                                                                                                                    |tokens                                                                                                                                                                                                                                                                    |\n",
            "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|this process however afforded me no means of ascertaining the dimensions of my dungeon as i might make its circuit and return to the point whence i set out without being aware of the fact so perfectly uniform seemed the wall|[this, process, however, afforded, me, no, means, of, ascertaining, the, dimensions, of, my, dungeon, as, i, might, make, its, circuit, and, return, to, the, point, whence, i, set, out, without, being, aware, of, the, fact, so, perfectly, uniform, seemed, the, wall]|\n",
            "|it never once occurred to me that the fumbling might be a mere mistake                                                                                                                                                          |[it, never, once, occurred, to, me, that, the, fumbling, might, be, a, mere, mistake]                                                                                                                                                                                     |\n",
            "|in his left hand was a gold snuff box from which as he capered down the hill cutting all manner of fantastic steps he took snuff incessantly with an air of the greatest possible self satisfaction                             |[in, his, left, hand, was, a, gold, snuff, box, from, which, as, he, capered, down, the, hill, cutting, all, manner, of, fantastic, steps, he, took, snuff, incessantly, with, an, air, of, the, greatest, possible, self, satisfaction]                                  |\n",
            "|how lovely is spring as we looked from windsor terrace on the sixteen fertile counties spread beneath speckled by happy cottages and wealthier towns all looked as in former years heart cheering and fair                      |[how, lovely, is, spring, as, we, looked, from, windsor, terrace, on, the, sixteen, fertile, counties, spread, beneath, speckled, by, happy, cottages, and, wealthier, towns, all, looked, as, in, former, years, heart, cheering, and, fair]                             |\n",
            "|finding nothing else not even gold the superintendent abandoned his attempts but a perplexed look occasionally steals over his countenance as he sits thinking at his desk                                                      |[finding, nothing, else, not, even, gold, the, superintendent, abandoned, his, attempts, but, a, perplexed, look, occasionally, steals, over, his, countenance, as, he, sits, thinking, at, his, desk]                                                                    |\n",
            "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "\n",
            "Data after Tokenization (Test):\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|cleaned_text                                                                                                                                                                                                                                                                                                                       |tokens                                                                                                                                                                                                                                                                                                                                                                                            |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|still as i urged our leaving ireland with such inquietude and impatience my father thought it best to yield                                                                                                                                                                                                                        |[still, as, i, urged, our, leaving, ireland, with, such, inquietude, and, impatience, my, father, thought, it, best, to, yield]                                                                                                                                                                                                                                                                   |\n",
            "|if a fire wanted fanning it could readily be fanned with a newspaper and as the government grew weaker i have no doubt that leather and iron acquired durability in proportion for in a very short time there was not a pair of bellows in all rotterdam that ever stood in need of a stitch or required the assistance of a hammer|[if, a, fire, wanted, fanning, it, could, readily, be, fanned, with, a, newspaper, and, as, the, government, grew, weaker, i, have, no, doubt, that, leather, and, iron, acquired, durability, in, proportion, for, in, a, very, short, time, there, was, not, a, pair, of, bellows, in, all, rotterdam, that, ever, stood, in, need, of, a, stitch, or, required, the, assistance, of, a, hammer]|\n",
            "|and when they had broken down the frail door they found only this two cleanly picked human skeletons on the earthen floor and a number of singular beetles crawling in the shadowy corners                                                                                                                                         |[and, when, they, had, broken, down, the, frail, door, they, found, only, this, two, cleanly, picked, human, skeletons, on, the, earthen, floor, and, a, number, of, singular, beetles, crawling, in, the, shadowy, corners]                                                                                                                                                                      |\n",
            "|while i was thinking how i should possibly manage without them one actually tumbled out of my head and rolling down the steep side of the steeple lodged in the rain gutter which ran along the eaves of the main building                                                                                                         |[while, i, was, thinking, how, i, should, possibly, manage, without, them, one, actually, tumbled, out, of, my, head, and, rolling, down, the, steep, side, of, the, steeple, lodged, in, the, rain, gutter, which, ran, along, the, eaves, of, the, main, building]                                                                                                                              |\n",
            "|i am not sure to what limit his knowledge may extend                                                                                                                                                                                                                                                                               |[i, am, not, sure, to, what, limit, his, knowledge, may, extend]                                                                                                                                                                                                                                                                                                                                  |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "\n",
            "Data after Stop Words Removal (Train):\n",
            "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|tokens                                                                                                                                                                                                                                                                    |filtered_tokens                                                                                                                                                                   |\n",
            "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|[this, process, however, afforded, me, no, means, of, ascertaining, the, dimensions, of, my, dungeon, as, i, might, make, its, circuit, and, return, to, the, point, whence, i, set, out, without, being, aware, of, the, fact, so, perfectly, uniform, seemed, the, wall]|[process, however, afforded, means, ascertaining, dimensions, dungeon, might, make, circuit, return, point, whence, set, without, aware, fact, perfectly, uniform, seemed, wall]  |\n",
            "|[it, never, once, occurred, to, me, that, the, fumbling, might, be, a, mere, mistake]                                                                                                                                                                                     |[never, occurred, fumbling, might, mere, mistake]                                                                                                                                 |\n",
            "|[in, his, left, hand, was, a, gold, snuff, box, from, which, as, he, capered, down, the, hill, cutting, all, manner, of, fantastic, steps, he, took, snuff, incessantly, with, an, air, of, the, greatest, possible, self, satisfaction]                                  |[left, hand, gold, snuff, box, capered, hill, cutting, manner, fantastic, steps, took, snuff, incessantly, air, greatest, possible, self, satisfaction]                           |\n",
            "|[how, lovely, is, spring, as, we, looked, from, windsor, terrace, on, the, sixteen, fertile, counties, spread, beneath, speckled, by, happy, cottages, and, wealthier, towns, all, looked, as, in, former, years, heart, cheering, and, fair]                             |[lovely, spring, looked, windsor, terrace, sixteen, fertile, counties, spread, beneath, speckled, happy, cottages, wealthier, towns, looked, former, years, heart, cheering, fair]|\n",
            "|[finding, nothing, else, not, even, gold, the, superintendent, abandoned, his, attempts, but, a, perplexed, look, occasionally, steals, over, his, countenance, as, he, sits, thinking, at, his, desk]                                                                    |[finding, nothing, else, even, gold, superintendent, abandoned, attempts, perplexed, look, occasionally, steals, countenance, sits, thinking, desk]                               |\n",
            "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "\n",
            "Data after Stop Words Removal (Test):\n",
            "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|tokens                                                                                                                                                                                                                                                                                                                                                                                            |filtered_tokens                                                                                                                                                                                                                      |\n",
            "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|[still, as, i, urged, our, leaving, ireland, with, such, inquietude, and, impatience, my, father, thought, it, best, to, yield]                                                                                                                                                                                                                                                                   |[still, urged, leaving, ireland, inquietude, impatience, father, thought, best, yield]                                                                                                                                               |\n",
            "|[if, a, fire, wanted, fanning, it, could, readily, be, fanned, with, a, newspaper, and, as, the, government, grew, weaker, i, have, no, doubt, that, leather, and, iron, acquired, durability, in, proportion, for, in, a, very, short, time, there, was, not, a, pair, of, bellows, in, all, rotterdam, that, ever, stood, in, need, of, a, stitch, or, required, the, assistance, of, a, hammer]|[fire, wanted, fanning, readily, fanned, newspaper, government, grew, weaker, doubt, leather, iron, acquired, durability, proportion, short, time, pair, bellows, rotterdam, ever, stood, need, stitch, required, assistance, hammer]|\n",
            "|[and, when, they, had, broken, down, the, frail, door, they, found, only, this, two, cleanly, picked, human, skeletons, on, the, earthen, floor, and, a, number, of, singular, beetles, crawling, in, the, shadowy, corners]                                                                                                                                                                      |[broken, frail, door, found, two, cleanly, picked, human, skeletons, earthen, floor, number, singular, beetles, crawling, shadowy, corners]                                                                                          |\n",
            "|[while, i, was, thinking, how, i, should, possibly, manage, without, them, one, actually, tumbled, out, of, my, head, and, rolling, down, the, steep, side, of, the, steeple, lodged, in, the, rain, gutter, which, ran, along, the, eaves, of, the, main, building]                                                                                                                              |[thinking, possibly, manage, without, one, actually, tumbled, head, rolling, steep, side, steeple, lodged, rain, gutter, ran, along, eaves, main, building]                                                                          |\n",
            "|[i, am, not, sure, to, what, limit, his, knowledge, may, extend]                                                                                                                                                                                                                                                                                                                                  |[sure, limit, knowledge, may, extend]                                                                                                                                                                                                |\n",
            "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "module 'nltk.downloader' has no attribute 'DownloadError'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-11-3178328451.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'corpora/wordnet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDownloadError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    578\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"\\n{sep}\\n{msg}\\n{sep}\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/wordnet\u001b[0m\n\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-11-3178328451.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'corpora/wordnet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0;32mexcept\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDownloadError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'wordnet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'nltk.downloader' has no attribute 'DownloadError'"
          ]
        }
      ],
      "source": [
        "# 2. Tokenization\n",
        "# Initialize the Tokenizer to split the cleaned text into individual words (tokens)\n",
        "tokenizer = Tokenizer(inputCol=\"cleaned_text\", outputCol=\"tokens\")\n",
        "\n",
        "# Apply tokenization to both DataFrames\n",
        "train_df = tokenizer.transform(train_df)\n",
        "test_df = tokenizer.transform(test_df)\n",
        "\n",
        "print(\"\\nData after Tokenization (Train):\")\n",
        "train_df.select(\"cleaned_text\", \"tokens\").show(5, truncate=False)\n",
        "print(\"\\nData after Tokenization (Test):\")\n",
        "test_df.select(\"cleaned_text\", \"tokens\").show(5, truncate=False)\n",
        "\n",
        "\n",
        "# 3. Stop Words Removal\n",
        "# Initialize the StopWordsRemover\n",
        "# PySpark's default stop words list is quite comprehensive.\n",
        "stopwords_remover = StopWordsRemover(inputCol=\"tokens\", outputCol=\"filtered_tokens\")\n",
        "\n",
        "# Apply stop words removal to both DataFrames\n",
        "train_df = stopwords_remover.transform(train_df)\n",
        "test_df = stopwords_remover.transform(test_df)\n",
        "\n",
        "print(\"\\nData after Stop Words Removal (Train):\")\n",
        "train_df.select(\"tokens\", \"filtered_tokens\").show(5, truncate=False)\n",
        "print(\"\\nData after Stop Words Removal (Test):\")\n",
        "test_df.select(\"tokens\", \"filtered_tokens\").show(5, truncate=False)\n",
        "\n",
        "\n",
        "# 4. Lemmatization (using a simple UDF)\n",
        "# PySpark does not have a built-in lemmatizer.\n",
        "# For simplicity, we'll use a basic lemmatization UDF.\n",
        "# For more advanced lemmatization, you would typically integrate NLTK or SpaCy within a UDF.\n",
        "# This example uses a very basic approach for demonstration.\n",
        "# In a real-world scenario, you'd use a more robust lemmatizer.\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import wordnet\n",
        "import nltk\n",
        "\n",
        "# Download necessary NLTK data (run this once)\n",
        "try:\n",
        "    nltk.data.find('corpora/wordnet')\n",
        "except nltk.downloader.DownloadError:\n",
        "    nltk.download('wordnet')\n",
        "try:\n",
        "    nltk.data.find('corpora/omw-1.4')\n",
        "except nltk.downloader.DownloadError:\n",
        "    nltk.download('omw-1.4')\n",
        "\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def get_wordnet_pos(word):\n",
        "    \"\"\"Map POS tag to first character used by WordNetLemmatizer\"\"\"\n",
        "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
        "    tag_dict = {\"J\": wordnet.ADJ,\n",
        "                \"N\": wordnet.NOUN,\n",
        "                \"V\": wordnet.VERB,\n",
        "                \"R\": wordnet.ADV}\n",
        "    return tag_dict.get(tag, wordnet.NOUN)\n",
        "\n",
        "def lemmatize_tokens(tokens):\n",
        "    if tokens is None:\n",
        "        return None\n",
        "    return [lemmatizer.lemmatize(token, get_wordnet_pos(token)) for token in tokens]\n",
        "\n",
        "# Register the UDF for lemmatization\n",
        "lemmatize_udf = udf(lemmatize_tokens, ArrayType(StringType()))\n",
        "\n",
        "# Apply lemmatization to the 'filtered_tokens' column\n",
        "train_df = train_df.withColumn(\"lemmas\", lemmatize_udf(train_df[\"filtered_tokens\"]))\n",
        "test_df = test_df.withColumn(\"lemmas\", lemmatize_udf(test_df[\"filtered_tokens\"]))\n",
        "\n",
        "print(\"\\nData after Lemmatization (Train):\")\n",
        "train_df.select(\"filtered_tokens\", \"lemmas\").show(5, truncate=False)\n",
        "print(\"\\nData after Lemmatization (Test):\")\n",
        "test_df.select(\"filtered_tokens\", \"lemmas\").show(5, truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pyspark.ml.feature import CountVectorizer, IDF\n",
        "from pyspark.ml.feature import Normalizer, Pipeline\n",
        "\n",
        "vectorizer = CountVectorizer(inputCol=\"lemmas\", outputCol = \"vectorized_tokens\")\n",
        "idf = IDF(inputCol=\"vectorized_tokens\", outputCol=\"tfidf\")\n",
        "normalizer = Normalizer(inputCol=\"tfidf\", outputCol=\"normalized_features\")\n",
        "pipeline = Pipeline(stages=[tokenizer, stopwords_remover, vectorizer, idf, normalizer])\n",
        "processed_data = pipeline.fit(train_df).transform(train_df)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
