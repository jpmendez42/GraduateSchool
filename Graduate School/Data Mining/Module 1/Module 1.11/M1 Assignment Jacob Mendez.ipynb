{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "khVZ7DoGDiBn",
   "metadata": {
    "id": "khVZ7DoGDiBn"
   },
   "source": [
    "# **`M.1.Introduction to data mining`**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f09fcd7",
   "metadata": {
    "id": "5f09fcd7"
   },
   "source": [
    "## **`assign.M.1.assignment.1`** - Data Mining with Covid Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ujMShg_DwKdx",
   "metadata": {
    "id": "ujMShg_DwKdx"
   },
   "source": [
    "### **`Overview and Directions`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "orcAiqUZAQ6Y",
   "metadata": {
    "id": "orcAiqUZAQ6Y"
   },
   "source": [
    "1. Import and manipulate a .csv file  \n",
    "2. Assess your Python Programming Skills  \n",
    "3. Other assignments are more challenging; use this to assess your skills.\n",
    "4. Prepare questions for a class discussion to help source additional tools. \n",
    "5. Perform tasks without assistance from clever sources.    \n",
    "\n",
    "#### **`Desired outcomes`**  \n",
    "- Experience Pandas dataframes to group, aggregate, find, sort, and calculate.  \n",
    "- Perform calculations to find best country, rank, and total items processed. \n",
    "- Note: Pandas is reviewed in Module 2 and quality resources provided below.  \n",
    "\n",
    "#### **`Additional resources`**  \n",
    "- [Daniel Chen](https://github.com/chendaniely/) is a **generous** Pandas master.  \n",
    "=> Purchase of his books is recommended; not a solicitation!    \n",
    "- [Chen,D.,(2022). Pandas for everyone, 2nd.Ed.](https://www.amazon.com/Pandas-Everyone-Analysis-Addison-Wesley-Analytics/dp/0137891156/ref=sr_1_1?crid=T9BF3HU24YFL&keywords=pandas+for+everyone&qid=1685205022&sprefix=pandas+for+everyone%2Caps%2C203&sr=8-1)  \n",
    "=> [groupby](https://github.com/chendaniely/2017-10-26-python_crash_course/blob/gh-pages/notebooks/07-groupby.ipynb) => [missing values](https://github.com/chendaniely/2017-10-26-python_crash_course/blob/gh-pages/notebooks/03-missing.ipynb) => [many more!](https://github.com/chendaniely/2017-10-26-python_crash_course/tree/gh-pages/notebooks)    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RNiLo5Rm9SM2",
   "metadata": {
    "id": "RNiLo5Rm9SM2"
   },
   "source": [
    "### **`Task.0`**  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wcrKuRsWXUW1",
   "metadata": {
    "id": "wcrKuRsWXUW1"
   },
   "source": [
    "#### **`Dataset`**\n",
    "- source information => COVID-19 variant [sequencing](https://www.cdc.gov/coronavirus/2019-ncov/variants/genomic-surveillance.html#:~:text=Scientists%20use%20a%20process%20called%20genomic%20sequencing%20to%20identify%20SARS,test%20positive%20for%20COVID%2D19) by countries.   \n",
    "Data fields    \n",
    "1. `location`: the country providing information.    \n",
    "2. `date`: data entry date.  \n",
    "3. `variant`: the COVID-19 variant for the entered record.  \n",
    "4. `num_sequences`: the number of sequences **processed** by country, variant, and date.   \n",
    "5. `num_sequences_total`: the number of sequences **available** by country, variant, and date.  \n",
    "6. `perc_sequences`: the percentage of the available sequences processed (*out of 100*)  \n",
    "`note:` each dataset row represents *one* variant by *one* country on *one* day.  \n",
    "\n",
    "**`Tasks`**  \n",
    "1. Locate and read dataset into a pandas.DataFrame called 'df' via  \n",
    "a. A Kaggle API; use existing or acquire; [Kaggle.covid.dataset](https://www.kaggle.com/yamqwe/omicron-covid19-variant-daily-cases?select=covid-variants.csv)  \n",
    "or  \n",
    "b. Class github URL or another .csv method like [Matthes, Ch.16](https://github.com/cosc-526/cosc.526.home.page/blob/main/textbook.Python.crash.course.matthes.pdf)    \n",
    "=> filename: [data.M.1.assignment.covid.data.csv](https://raw.githubusercontent.com/cosc-526/home.page/main/data.M.1.assignment.covid.data.csv)    \n",
    "=>**consider** reading a Github data URL requires a path to **raw data**    \n",
    "2. Display the DataFrame's first 5 rows.  \n",
    "3. Display descriptive stats confirming: 100,416 data records.  \n",
    "4. Round DataFrame to 1 decimal place!   \n",
    "\n",
    "**`Useful links`**  \n",
    "[Built-in Functions](https://docs.python.org/3/library/functions.html#built-in-functions)  \n",
    "[pandas.DataFrame documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "J6JeWBO2Cw78",
   "metadata": {
    "id": "J6JeWBO2Cw78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of dataL:   location        date    variant  num_sequences  perc_sequences  \\\n",
      "0   Angola  2020-07-06      Alpha              0             0.0   \n",
      "1   Angola  2020-07-06  B.1.1.277              0             0.0   \n",
      "2   Angola  2020-07-06  B.1.1.302              0             0.0   \n",
      "3   Angola  2020-07-06  B.1.1.519              0             0.0   \n",
      "4   Angola  2020-07-06    B.1.160              0             0.0   \n",
      "\n",
      "   num_sequences_total  \n",
      "0                    3  \n",
      "1                    3  \n",
      "2                    3  \n",
      "3                    3  \n",
      "4                    3  \n",
      "\n",
      "Descriptive Stats:        num_sequences  perc_sequences  num_sequences_total\n",
      "count       100416.0        100416.0             100416.0\n",
      "mean            72.2             6.2               1509.6\n",
      "std           1669.3            21.9               8445.3\n",
      "min              0.0            -0.0                  1.0\n",
      "25%              0.0             0.0                 12.0\n",
      "50%              0.0             0.0                 59.0\n",
      "75%              0.0             0.0                394.0\n",
      "max         142280.0           100.0             146170.0\n"
     ]
    }
   ],
   "source": [
    "#=>Enter answer\n",
    "import pandas as pd  \n",
    "url = 'https://raw.githubusercontent.com/cosc-526/home.page/main/data.M.1.assignment.covid.data.csv'\n",
    "df = pd.read_csv(url, delimiter=',')\n",
    "print(f\"First 5 rows of dataL: {df[0:5]}\")\n",
    "print(f\"\\nDescriptive Stats: {df.describe().round(1)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4z6COkzkC2KU",
   "metadata": {
    "id": "4z6COkzkC2KU"
   },
   "source": [
    "#### **`Task.0 - Expected Outcome`**  \n",
    "```\n",
    "DataFrame header\n",
    "  location  date        variant  num_sequences  perc_sequences  num_sequences_total\n",
    "0   Angola  2020-07-06      Alpha              0             0.0   3\n",
    "1   Angola  2020-07-06  B.1.1.277              0             0.0   3\n",
    "2   Angola  2020-07-06  B.1.1.302              0             0.0   3\n",
    "3   Angola  2020-07-06  B.1.1.519              0             0.0   3\n",
    "4   Angola  2020-07-06    B.1.160              0             0.0   3\n",
    "\n",
    "Dataframe descriptive statistics, rounded to tenths\n",
    "       num_sequences  perc_sequences  num_sequences_total\n",
    "count       100416.0        100416.0             100416.0\n",
    "mean            72.0             6.0               1510.0\n",
    "std           1669.0            22.0               8445.0\n",
    "min              0.0            -0.0                  1.0\n",
    "25%              0.0             0.0                 12.0\n",
    "50%              0.0             0.0                 59.0\n",
    "75%              0.0             0.0                394.0\n",
    "max         142280.0           100.0             146170.0 \n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760c5a8f",
   "metadata": {
    "id": "760c5a8f"
   },
   "source": [
    "### **`Task.1`** - Find uncommon variants  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZGy_VBO4DDyd",
   "metadata": {
    "id": "ZGy_VBO4DDyd"
   },
   "source": [
    "The U.S. experienced the COVID-19 `Alpha`, `Delta`, `Omicron`  \n",
    "\n",
    "**`Tasks`**  \n",
    "0. In whatever object you like, e.g. list, dataframe, etc  \n",
    "1. Get unique variant items for category: **`US_and_other`**  \n",
    "=> where variants == [US, `non_who`, `others`]  \n",
    "2. Get unique variant items for category: **`nonUS_and_other`**  \n",
    "=> where variants != [US, `non_who`, `others`]  \n",
    "3. Print your chosen objects to display unique variant categories.  \n",
    "4. Show a total unique count for each, and total for dataset,\n",
    "\n",
    "**`Useful links`**   \n",
    "- [len()](https://docs.python.org/3/library/functions.html#len)\n",
    "- [list comprehension w Bro Code](https://www.youtube.com/watch?v=fcLDzKH_5XM)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "vxMduRg5Cj5u",
   "metadata": {
    "id": "vxMduRg5Cj5u"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total US Variants: {'Alpha', 'others', 'non_who', 'Delta', 'Omicron'}\n",
      "Number of Unique Variants: 5\n",
      "['B.1.1.277' 'B.1.1.302' 'B.1.1.519' 'B.1.160' 'B.1.177' 'B.1.221'\n",
      " 'B.1.258' 'B.1.367' 'B.1.620' 'Beta' 'Epsilon' 'Eta' 'Gamma' 'Iota'\n",
      " 'Kappa' 'Lambda' 'Mu' 'S:677H.Robin1' 'S:677P.Pelican']\n",
      "Number of Non-US variants: 19\n",
      "Grand total of Variants: 24\n"
     ]
    }
   ],
   "source": [
    "#=>Enter answer  \n",
    "USVars = {\"Alpha\", \"Delta\", \"Omicron\"}\n",
    "otherVars = {\"non_who\", \"others\"}\n",
    "\n",
    "print(f\"Total US Variants: {USVars.union(otherVars)}\")\n",
    "print(f\"Number of Unique Variants: {len(USVars.union(otherVars))}\")\n",
    "\n",
    "NotUSVars = df[~df['variant'].isin(USVars.union(otherVars))]\n",
    "\n",
    "NonUSVars = NotUSVars['variant'].unique()\n",
    "\n",
    "print(NonUSVars)\n",
    "print(f\"Number of Non-US variants: {len(NonUSVars)}\")\n",
    "print(f\"Grand total of Variants: {len(USVars.union(otherVars).union(NonUSVars))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jBOVMJ0zck9a",
   "metadata": {
    "id": "jBOVMJ0zck9a"
   },
   "source": [
    "#### **`Task.1 - Expected Outcome`**  \n",
    "```\n",
    "note: organization of output can vary widely!  \n",
    "\n",
    "['Alpha', 'Delta', 'Omicron', 'others', 'non_who']  \n",
    "\n",
    "total US + other =  5\n",
    "\n",
    "['B.1.1.277', 'B.1.1.302', 'B.1.1.519', 'B.1.160', 'B.1.177', 'B.1.221',  \n",
    " 'B.1.258', 'B.1.367', 'B.1.620', 'Beta', 'Epsilon', 'Eta', 'Gamma', 'Iota',  \n",
    "  'Kappa', 'Lambda', 'Mu', 'S:677H.Robin1', 'S:677P.Pelican']   \n",
    "  \n",
    "total nonUS+other =  19   \n",
    "\n",
    "total unique variants =  24 \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aB6-dtiH5OSq",
   "metadata": {
    "id": "aB6-dtiH5OSq"
   },
   "source": [
    "### **`Task.2`** - Find the most processed variant  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bRbxoQb9rbN9",
   "metadata": {
    "id": "bRbxoQb9rbN9"
   },
   "source": [
    "**Tasks**  \n",
    "1. Which variant of COVID-19 has the most sequences processed?  \n",
    "2. Store and print the result in a string called **`variant_most_proc`**  \n",
    "\n",
    "**Useful links**  \n",
    "[pd.DataFrame.groupby](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html#pandas-dataframe-groupby), [pd.DataFrame.aggregate](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.aggregate.html#pandas-dataframe-aggregate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "JoFZ2N-WFDH1",
   "metadata": {
    "id": "JoFZ2N-WFDH1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Variant: Delta\n"
     ]
    }
   ],
   "source": [
    "#=>Enter Your Solution\n",
    "variant_most_proc = df.groupby('variant').aggregate({'num_sequences' : 'sum'})\n",
    "\n",
    "print(f\"Top Variant: {variant_most_proc['num_sequences'].idxmax()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5uAWiinsdBi2",
   "metadata": {
    "id": "5uAWiinsdBi2"
   },
   "source": [
    "#### **`Task.2 - Expected Outcome`**  \n",
    "```\n",
    "Delta  \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663db8ac",
   "metadata": {
    "id": "663db8ac"
   },
   "source": [
    "### **`Task.3`** - Find the best country at processing ALL variant sequences  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ny95wr5_sQhK",
   "metadata": {
    "id": "ny95wr5_sQhK"
   },
   "source": [
    "**`Tasks`**  \n",
    "1. Which country did the best processing **all** categories.    \n",
    "2. Store the result in a string called **`best_proc_country`**  \n",
    "3. The outcome is a single country.  \n",
    "4. **consider** df.groupby(\"location\").aggregate({\"num_sequences\": \"sum\", \"num_sequences_total\": \"sum\"})\n",
    "\n",
    "**`Useful links`**  \n",
    "[youtube: aggregate with groupby and .agg or .aggregate](https://www.youtube.com/watch?v=PNzlx3CjqAE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "75c31b41",
   "metadata": {
    "id": "75c31b41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "location\n",
      "Angola           5.233017\n",
      "Argentina        5.295149\n",
      "Aruba            4.586111\n",
      "Australia        5.532250\n",
      "Austria          4.844661\n",
      "                   ...   \n",
      "United States    4.845368\n",
      "Uruguay          7.264174\n",
      "Vietnam          4.180517\n",
      "Zambia           5.837810\n",
      "Zimbabwe         5.290330\n",
      "Name: percent, Length: 121, dtype: float64\n",
      "\n",
      "Best country: Cyprus\n"
     ]
    }
   ],
   "source": [
    "#=>Enter Your Solution\n",
    "proc_by_country = df.groupby('location').aggregate({'num_sequences': 'sum', 'num_sequences_total' :'sum'})\n",
    "\n",
    "proc_by_country[\"percent\"] = (proc_by_country['num_sequences'] / proc_by_country['num_sequences_total']) * 100\n",
    "\n",
    "proc_country = proc_by_country[\"percent\"].sort_values(ascending=False)\n",
    "\n",
    "print(proc_by_country[\"percent\"])\n",
    "best_proc_country = proc_country.idxmax()\n",
    "\n",
    "print(f\"\\nBest country: {best_proc_country}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "y0bRJhZLdKBu",
   "metadata": {
    "id": "y0bRJhZLdKBu"
   },
   "source": [
    "#### **`Task.3 - Expected Outcome`**\n",
    "```\n",
    "Total percent performed by country \n",
    "\n",
    "location                percent\n",
    "Cyprus                  8.19\n",
    "Hungary                 7.96\n",
    "Egypt                   7.77\n",
    "United Arab Emirates    7.58\n",
    "Uruguay                 7.26\n",
    "                        ... \n",
    "Seychelles              4.25\n",
    "Fiji                    4.23\n",
    "Slovakia                4.23\n",
    "Brunei                  4.22\n",
    "Vietnam                 4.18\n",
    "Name: perc_sequences, Length: 121, dtype: float64 \n",
    "\n",
    "the best country is =>  Cyprus\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d1d3a0",
   "metadata": {
    "id": "11d1d3a0"
   },
   "source": [
    "### **`Task.4a`** - Find the best country at processing specific variant sequences  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Jxd-0IN00go_",
   "metadata": {
    "id": "Jxd-0IN00go_"
   },
   "source": [
    "**`Tasks`**  \n",
    "1. Which country is best at processing sequences for Alpha, Delta, and Omicron variants?    \n",
    "2. Store and print the result in a string called **`best_proc_country_ADO`** \n",
    "3. The final output is a single country.  \n",
    "\n",
    "**`Useful links`** \n",
    "- ibid  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "fcafdd2e",
   "metadata": {
    "id": "fcafdd2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best country for processing ADO is Vietnam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16502/1771196933.py:3: FutureWarning: The provided callable <built-in function sum> is currently using SeriesGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  Ado_totals = Ado.groupby('location').aggregate({\n"
     ]
    }
   ],
   "source": [
    "#=>Enter Your Solution\n",
    "Ado = df[df['variant'].isin(['Alpha', 'Delta', 'Omicron'])]\n",
    "Ado_totals = Ado.groupby('location').aggregate({\n",
    "    'num_sequences' : 'sum',\n",
    "    'num_sequences_total' : sum\n",
    "})\n",
    "Ado_totals[\"percent\"] = (Ado_totals['num_sequences'] / Ado_totals['num_sequences_total']) * 100\n",
    "best_proc_country_ADO = Ado_totals[\"percent\"].idxmax()\n",
    "\n",
    "print(f\"The best country for processing ADO is {best_proc_country_ADO}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fvANdWH2kOqc",
   "metadata": {
    "id": "fvANdWH2kOqc"
   },
   "source": [
    "#### **`Task.4a - Expected Outcome`**  \n",
    "```\n",
    "best_proc_country_ADO = Vietnam  \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ccb8782",
   "metadata": {
    "id": "9ccb8782"
   },
   "source": [
    "### **`Task.4b`** - Find the United States ranking for processing Alpha, Delta, and Omicron  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uS-CWHXDFnlB",
   "metadata": {
    "id": "uS-CWHXDFnlB"
   },
   "source": [
    "**`Tasks`**  \n",
    "Given the outcome in 4a\n",
    "1. Find the positional index value for the US ranking for processing sequences for Alpha, Delta, an Omicron variants.   \n",
    "2. Store and print the ranking as an integer in a **us_ranking** variable.  \n",
    "3. Ensure your ranking scale reflects a scale starting at 1.  \n",
    "4. As a refresher, Python indexing starts at 0.  \n",
    "\n",
    "**`Useful links`** \n",
    "- [enumerate](https://docs.python.org/3/library/functions.html#enumerate)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "038e81b5",
   "metadata": {
    "id": "038e81b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "United States ranking: 57\n"
     ]
    }
   ],
   "source": [
    "#=>Enter Your Solution\n",
    "Ado_sorted = Ado_totals.sort_values(by='percent', ascending=False)\n",
    "us_ranking = Ado_sorted.index.get_loc('United States') + 1\n",
    "print(f\"United States ranking: {us_ranking}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "G5SUmnTckQBM",
   "metadata": {
    "id": "G5SUmnTckQBM"
   },
   "source": [
    "#### **`Task.4b - Expected Outcome`**  \n",
    "```\n",
    "United States ranking = 57  \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283e46d3",
   "metadata": {
    "id": "283e46d3"
   },
   "source": [
    "### **`Task.5.<final.task>` - Write instructions for a jr. data scientist assignment**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qhqwnKBcvW7R",
   "metadata": {
    "id": "qhqwnKBcvW7R"
   },
   "source": [
    "**`Task =>`**  \n",
    "- Write clear and precise directions that enable your  new junior  \n",
    "- data analyst, aka \"Jr,\" to modify and fix code that you provide.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913dpFR0Fp1E",
   "metadata": {
    "id": "913dpFR0Fp1E"
   },
   "source": [
    "#### **`Grading requirements=>`**  \n",
    "A clear and precise explanation of specific activities for production code your boss needs but you dont have time to fix.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2mN_TFHdT1Vg",
   "metadata": {
    "id": "2mN_TFHdT1Vg"
   },
   "source": [
    "Data science requires clear explanations of tasks, methodology, and effective communication with peers. To help the new junior analyst complete their first assignment, provide a concise and precise description including  \n",
    "\n",
    "1. `Sample Outcome`\n",
    "Deliver a comprehensive report summarizing findings and insights from data analysis. Include, as needed, desired outcome format, data objects, and visualizations.  \n",
    "\n",
    "2. `Python Code Explanation`\n",
    "Use plain language to describe specific Python code to achieve the desired outcome. Refer to pandas, Python, and other library documentation to incorporate particular language.  \n",
    "\n",
    "3. `Consider Deprecated Functions`\n",
    "The provided code is outdated and broken. Encourage problem-solving skills and leverage previous experience with similar tasks. Provide relevant links for reverse engineering.  \n",
    "\n",
    "**`Additional personnel considerations`**\n",
    "4. `Plain Language Explanation`\n",
    "Consider the junior analyst's background in C and provide clear and unambiguous instructions.  \n",
    "\n",
    "5. `Documentation Reference`\n",
    "Emphasize where to consult pandas, Python, and other library documentation to discern code mechanics and clarify concepts.  \n",
    "\n",
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "TOdZMTe-Rcl_",
   "metadata": {
    "id": "TOdZMTe-Rcl_"
   },
   "source": [
    "`Your manager's original request => [memo substrate]` \n",
    "\n",
    "`\"hey! i need by lunch` the processed sequences per country on any date`  \n",
    "because as CFO wants to crunch numbers this afternoon - thx Lambda\"\n",
    "\n",
    "1. Determine the percentage of processed sequences for the Alpha, Delta, and Omicron variants in the US.  \n",
    "2. Store the result as a dictionary where keys are variant names and values are percentages.  \n",
    "3. Save in variable = proc_seq_us\n",
    "\n",
    "`=> Other implied items based on same exercise for manager last year`\n",
    "- Determine each country's total processed sequences for Omicron on December 27, 2021 or any other date entered (date updated from 2020).\n",
    "- provide country name and # processed sequences\n",
    "- bidirectional sorting\n",
    "- store outcomes in tuple like mytuple(country_name, processed_sequen, ) \n",
    "- variables totals like `total_omicron_2021`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sMFoLYaXlRGZ",
   "metadata": {
    "id": "sMFoLYaXlRGZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha Percentage: 0.00\n",
      "Delta Percentage: 49.55\n"
     ]
    }
   ],
   "source": [
    "#=> Enter Your Solution; i.e. write memo here\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Read Data from URL\n",
    "url = \"https://raw.githubusercontent.com/cosc-526/home.page/main/data.M.1.assignment.covid.data.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Filter for the three variants Alpha, Delta, Omicron\n",
    "AdoVars = ['Alpha', 'Delta', 'Omicron']\n",
    "# CHANGE THIS VALUE IF YOU WANT A NEW DATE\n",
    "AdoDate = '2021-12-27' \n",
    "filters = df[\n",
    "    (df['variant'].isin(AdoVars)) &\n",
    "    (df['location'] == 'United States') &\n",
    "    (df['date'] == AdoDate)\n",
    "]\n",
    "\n",
    "# Get the percentage of processed sequences for each variant\n",
    "# The formula is num_sequences / num_sequences_total * 100\n",
    "proc_seq_us = {}\n",
    "\n",
    "# Loop through each variant, getting the total per variant\n",
    "for variant in AdoVars:\n",
    "    subset = filters[filters['variant'] == variant]\n",
    "    if subset['num_sequences'].sum() > 0:\n",
    "        proc_seq_us[variant] = (subset['num_sequences'].sum() / subset['num_sequences_total'].sum()) * 100\n",
    "\n",
    "\n",
    "# Print The Results\n",
    "print(f\"Alpha Percentage: {proc_seq_us[\"Alpha\"]:.2f}\")\n",
    "print(f\"Delta Percentage: {proc_seq_us[\"Delta\"]:.2f}\")\n",
    "print(f\"Omicron Percentage: {proc_seq_us[\"Omicron\"]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uV6K5AkAfDET",
   "metadata": {
    "id": "uV6K5AkAfDET"
   },
   "source": [
    "#### `5a - code you found from last year's excercise `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qUkhMZD8T40i",
   "metadata": {
    "id": "qUkhMZD8T40i"
   },
   "outputs": [],
   "source": [
    "#=> I of III - broken code last year\n",
    "import pandas as pd\n",
    "\n",
    "#Read the data file\n",
    "url = \"https://github.com/cosc-526/home.page/raw/main/data.M.1.assignment.covid.data.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "### Partially working code\n",
    "# total_omicron_2021 = []\n",
    "# #5.1 \n",
    "# df = df.set_index(\"location\")\n",
    "# #5.2\n",
    "# df = df.loc[df6[\"date\"] == \"2021-12-27\"]\n",
    "# #5.3\n",
    "# df = df6.loc[df6[\"variant\"] == \"Omicron\"]\n",
    "# #5.3\n",
    "# df = df6[\"num_sequences\"]\n",
    "# #5.4\n",
    "#  = list(zip(df.index, df))\n",
    "# #5.5\n",
    "# df7 = pd.DataFrame(sorted(missing, key=lambda x: x[1], reverse=True))\n",
    "# print(df7)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dzXyv7kGZlBP",
   "metadata": {
    "id": "dzXyv7kGZlBP"
   },
   "source": [
    "##### **`5a - Expected Outcome`**  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "g1qcVGxqavtv",
   "metadata": {
    "id": "g1qcVGxqavtv"
   },
   "source": [
    "```\n",
    "0\t                1\n",
    "0\tUnited Kingdom\t52456\n",
    "1\tUnited States\t  24681\n",
    "2\tDenmark\t        3331\n",
    "3\tGermany\t        1701\n",
    "4\tIsrael\t        1578\n",
    "...\t...\t...\n",
    "59\tVietnam\t      1\n",
    "60\tMoldova\t      0\n",
    "61\tMonaco\t      0\n",
    "62\tNepal\t        0\n",
    "63\tSouth Korea \t0\n",
    "64 rows × 2 columns\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5G3szw10bNTr",
   "metadata": {
    "id": "5G3szw10bNTr"
   },
   "source": [
    "#### `5b - code you found from last year's excercise `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6cf6efa9",
   "metadata": {
    "id": "6cf6efa9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Alpha': 11.520951617373877, 'Delta': 63.76796208057254, 'Omicron': 1.370817855027461}\n"
     ]
    }
   ],
   "source": [
    "#=> II of III - broken code last year\n",
    "\n",
    "proc_seq_us = {}\n",
    "df2 = df.groupby([\"location\", \"variant\"]).aggregate({\n",
    "    \"num_sequences\": \"sum\",\n",
    "    \"num_sequences_total\": \"sum\",\n",
    "})\n",
    "df2[\"perc_sequences\"] = (df2[\"num_sequences\"] / df2[\"num_sequences_total\"]) * 100\n",
    "df2 = df2.loc[(\"United States\", [\"Alpha\", \"Delta\", \"Omicron\"]), :].loc[\"United States\"]\n",
    "df2 = df2[\"perc_sequences\"]\n",
    "proc_seq_us = df2.to_dict()\n",
    "print(proc_seq_us)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "NfYB_LjbZ_zq",
   "metadata": {
    "id": "NfYB_LjbZ_zq"
   },
   "source": [
    "##### **`5b - Expected Outcome`**  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_TI3iusnbUbO",
   "metadata": {
    "id": "_TI3iusnbUbO"
   },
   "source": [
    "```\n",
    "{'Alpha': 11.520951617373877, 'Delta': 63.76796208057254, \n",
    "                                                'Omicron': 1.370817855027461}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ySKYi-77bbXc",
   "metadata": {
    "id": "ySKYi-77bbXc"
   },
   "source": [
    "#### `5c - code you found from last year's excercise `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ilcLFMXTW9jG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ilcLFMXTW9jG",
    "outputId": "2b827e05-e959-4580-861d-518facb7c1c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 0      1\n",
      "0   United Kingdom  52456\n",
      "1    United States  24681\n",
      "2          Denmark   3331\n",
      "3          Germany   1701\n",
      "4           Israel   1578\n",
      "..             ...    ...\n",
      "59         Vietnam      1\n",
      "60         Moldova      0\n",
      "61          Monaco      0\n",
      "62           Nepal      0\n",
      "63     South Korea      0\n",
      "\n",
      "[64 rows x 2 columns]\n",
      "[('United Kingdom', 52456), ('United States', 24681), ('Denmark', 3331), ('Germany', 1701), ('Israel', 1578), ('Australia', 1319), ('Switzerland', 514), ('France', 509), ('Italy', 486), ('Belgium', 464), ('Spain', 461), ('Sweden', 434), ('Chile', 260), ('Netherlands', 254), ('Singapore', 249), ('Mexico', 240), ('Turkey', 202), ('India', 174), ('Brazil', 147), ('Botswana', 142), ('Indonesia', 128), ('Japan', 118), ('Portugal', 118), ('Argentina', 80), ('New Zealand', 63), ('South Africa', 61), ('Lithuania', 50), ('Czechia', 49), ('Georgia', 46), ('Russia', 45), ('Colombia', 37), ('Sri Lanka', 37), ('Hong Kong', 35), ('Malta', 34), ('Poland', 28), ('Ecuador', 26), ('Canada', 25), ('Jordan', 22), ('Malawi', 21), ('Cambodia', 18), ('Norway', 17), ('Morocco', 15), ('Senegal', 15), ('Costa Rica', 14), ('Pakistan', 11), ('Nigeria', 10), ('Peru', 10), ('Brunei', 8), ('Slovakia', 8), ('Trinidad and Tobago', 8), ('Maldives', 7), ('Zambia', 7), ('Thailand', 6), ('Malaysia', 5), ('Bangladesh', 4), ('Romania', 3), ('Iran', 1), ('Oman', 1), ('Ukraine', 1), ('Vietnam', 1), ('Moldova', 0), ('Monaco', 0), ('Nepal', 0), ('South Korea', 0)]\n"
     ]
    }
   ],
   "source": [
    "#=> III of III - broken code last year\n",
    "\n",
    "total_omicron_2021 = []\n",
    "#5.1\n",
    "df6 = df.set_index(\"location\")\n",
    "#5.2\n",
    "df6 = df6.loc[df6[\"date\"] == \"2021-12-27\"]\n",
    "#5.3#\n",
    "df6 = df6.loc[df6[\"variant\"] == \"Omicron\"]\n",
    "#5.3\n",
    "df6 = df6[\"num_sequences\"]\n",
    "#5.4\n",
    "total_omicron_2021 = list(zip(df6.index, df6))\n",
    "#5.5\n",
    "df7 = pd.DataFrame(sorted(total_omicron_2021, key=lambda x: x[1], reverse=True))\n",
    "print(df7)\n",
    "total_omicron_2021 = sorted(total_omicron_2021, key=lambda x: x[1], reverse=True)\n",
    "print(total_omicron_2021)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "x3c3REubaSEx",
   "metadata": {
    "id": "x3c3REubaSEx"
   },
   "source": [
    "##### **`5c - Expected Outcome`**  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2JNdnFwTap_f",
   "metadata": {
    "id": "2JNdnFwTap_f"
   },
   "source": [
    "```\n",
    "                 0      1\n",
    "0   United Kingdom  52456\n",
    "1    United States  24681\n",
    "2          Denmark   3331\n",
    "3          Germany   1701\n",
    "4           Israel   1578\n",
    "..             ...    ...\n",
    "59         Vietnam      1\n",
    "60         Moldova      0\n",
    "61          Monaco      0\n",
    "62           Nepal      0\n",
    "63     South Korea      0\n",
    "[64 rows x 2 columns]\n",
    "\n",
    "#[('United Kingdom', 52456), ('United States', 24681), ('Denmark', 3331),\n",
    " ('Germany', 1701), ('Israel', 1578), ('Australia', 1319), ('Switzerland', 514),\n",
    "  ('France', 509), ('Italy', 486), ('Belgium', 464), ('Spain', 461), \n",
    "  ('Sweden', 434), ('Chile', 260), ('Netherlands', 254), ('Singapore', 249),\n",
    "  ('Mexico', 240), ('Turkey', 202), ('India', 174), ('Brazil', 147),\n",
    "   ('Botswana', 142), ('Indonesia', 128), ('Japan', 118), ('Portugal', 118),\n",
    "    ('Argentina', 80), ('New Zealand', 63), ('South Africa', 61), \n",
    "    ('Lithuania', 50), ('Czechia', 49), ('Georgia', 46), ('Russia', 45), \n",
    "    ('Colombia', 37), ('Sri Lanka', 37), ('Hong Kong', 35), ('Malta', 34),\n",
    "     ('Poland', 28), ('Ecuador', 26), ('Canada', 25), ('Jordan', 22), \n",
    "     ('Malawi', 21), ('Cambodia', 18), ('Norway', 17), ('Morocco', 15), \n",
    "     ('Senegal', 15), ('Costa Rica', 14), ('Pakistan', 11), ('Nigeria', 10),\n",
    "      ('Peru', 10), ('Brunei', 8), ('Slovakia', 8), ('Trinidad and Tobago', 8),\n",
    "       ('Maldives', 7), ('Zambia', 7), ('Thailand', 6), ('Malaysia', 5), \n",
    "       ('Bangladesh', 4), ('Romania', 3), ('Iran', 1), ('Oman', 1),\n",
    "        ('Ukraine', 1), ('Vietnam', 1), ('Moldova', 0), ('Monaco', 0), \n",
    "        ('Nepal', 0), ('South Korea', 0)]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kjA00fVqPjEm",
   "metadata": {
    "id": "kjA00fVqPjEm"
   },
   "source": [
    "## `M.1. Ensure Spark is Enabled`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2DzgneXkPhuC",
   "metadata": {
    "id": "2DzgneXkPhuC"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "JAVA_HOME is not set\n"
     ]
    },
    {
     "ename": "PySparkRuntimeError",
     "evalue": "[JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPySparkRuntimeError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SparkSession\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#Create a SparkSession\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m spark \u001b[38;5;241m=\u001b[39m \u001b[43mSparkSession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappName\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mOmicron Sequences\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetOrCreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(spark)\n\u001b[1;32m      6\u001b[0m spark\u001b[38;5;241m.\u001b[39mstop()\n",
      "File \u001b[0;32m~/CodeSpace/.venv/lib/python3.12/site-packages/pyspark/sql/session.py:556\u001b[0m, in \u001b[0;36mSparkSession.Builder.getOrCreate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    554\u001b[0m     sparkConf\u001b[38;5;241m.\u001b[39mset(key, value)\n\u001b[1;32m    555\u001b[0m \u001b[38;5;66;03m# This SparkContext may be an existing one.\u001b[39;00m\n\u001b[0;32m--> 556\u001b[0m sc \u001b[38;5;241m=\u001b[39m \u001b[43mSparkContext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetOrCreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msparkConf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[38;5;66;03m# Do not update `SparkConf` for existing `SparkContext`, as it's shared\u001b[39;00m\n\u001b[1;32m    558\u001b[0m \u001b[38;5;66;03m# by all sessions.\u001b[39;00m\n\u001b[1;32m    559\u001b[0m session \u001b[38;5;241m=\u001b[39m SparkSession(sc, options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options)\n",
      "File \u001b[0;32m~/CodeSpace/.venv/lib/python3.12/site-packages/pyspark/core/context.py:523\u001b[0m, in \u001b[0;36mSparkContext.getOrCreate\u001b[0;34m(cls, conf)\u001b[0m\n\u001b[1;32m    521\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    522\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 523\u001b[0m         \u001b[43mSparkContext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mSparkConf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    524\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    525\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context\n",
      "File \u001b[0;32m~/CodeSpace/.venv/lib/python3.12/site-packages/pyspark/core/context.py:205\u001b[0m, in \u001b[0;36mSparkContext.__init__\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls, udf_profiler_cls, memory_profiler_cls)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gateway \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m gateway\u001b[38;5;241m.\u001b[39mgateway_parameters\u001b[38;5;241m.\u001b[39mauth_token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    201\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are trying to pass an insecure Py4j gateway to Spark. This\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    202\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is not allowed as it is a security risk.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    203\u001b[0m     )\n\u001b[0;32m--> 205\u001b[0m \u001b[43mSparkContext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ensure_initialized\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgateway\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgateway\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_init(\n\u001b[1;32m    208\u001b[0m         master,\n\u001b[1;32m    209\u001b[0m         appName,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    219\u001b[0m         memory_profiler_cls,\n\u001b[1;32m    220\u001b[0m     )\n",
      "File \u001b[0;32m~/CodeSpace/.venv/lib/python3.12/site-packages/pyspark/core/context.py:444\u001b[0m, in \u001b[0;36mSparkContext._ensure_initialized\u001b[0;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    443\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_gateway:\n\u001b[0;32m--> 444\u001b[0m         SparkContext\u001b[38;5;241m.\u001b[39m_gateway \u001b[38;5;241m=\u001b[39m gateway \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mlaunch_gateway\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    445\u001b[0m         SparkContext\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;241m=\u001b[39m SparkContext\u001b[38;5;241m.\u001b[39m_gateway\u001b[38;5;241m.\u001b[39mjvm\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m instance:\n",
      "File \u001b[0;32m~/CodeSpace/.venv/lib/python3.12/site-packages/pyspark/java_gateway.py:111\u001b[0m, in \u001b[0;36mlaunch_gateway\u001b[0;34m(conf, popen_kwargs)\u001b[0m\n\u001b[1;32m    108\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.1\u001b[39m)\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(conn_info_file):\n\u001b[0;32m--> 111\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PySparkRuntimeError(\n\u001b[1;32m    112\u001b[0m         errorClass\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJAVA_GATEWAY_EXITED\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    113\u001b[0m         messageParameters\u001b[38;5;241m=\u001b[39m{},\n\u001b[1;32m    114\u001b[0m     )\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(conn_info_file, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m info:\n\u001b[1;32m    117\u001b[0m     gateway_port \u001b[38;5;241m=\u001b[39m read_int(info)\n",
      "\u001b[0;31mPySparkRuntimeError\u001b[0m: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number."
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "#Create a SparkSession\n",
    "spark = SparkSession.builder.appName(\"Omicron Sequences\").getOrCreate()\n",
    "print(spark)\n",
    "spark.stop()\n",
    "\n",
    "### If this cell fails, you may need another Notebook environment!\n",
    "\n",
    "# I will try using another environment"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "el9sjRdm9gjv",
    "7o91Ig5QKVif",
    "MqZm_iFTPI7f",
    "JfIew_dgmpCQ",
    "kRoOscDyqoCO",
    "wcrKuRsWXUW1",
    "913dpFR0Fp1E",
    "kjA00fVqPjEm"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
